{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BU9TbKtIaKIE"
   },
   "source": [
    "# SP_Dataset_Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBm4RgoeaYBr"
   },
   "source": [
    "### Data\n",
    "1. Company Financials\n",
    "2. Company Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8267,
     "status": "ok",
     "timestamp": 1553865878414,
     "user": {
      "displayName": "VIPUL SHARMA",
      "photoUrl": "https://lh6.googleusercontent.com/-B7fONb4kgNw/AAAAAAAAAAI/AAAAAAAABEo/XWJaOukizlg/s64/photo.jpg",
      "userId": "02912111327623795170"
     },
     "user_tz": -330
    },
    "id": "Ef6gE-VYKZDL",
    "outputId": "5c90a9ed-648f-417d-b55f-df3b0dcb2656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/vdrive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "\"\"\"\n",
    "No need to execute this block when working on local system.\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/vdrive\", force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GQ6CA5RgLWpH"
   },
   "outputs": [],
   "source": [
    "# Files to process\n",
    "\"\"\"\n",
    "Modify the locations below as per your directory struture.\n",
    "\"\"\"\n",
    "root_dir = \"/content/vdrive/My Drive/Colab Notebooks/Projects/Bondai/SP 500/data/\"\n",
    "do_file = root_dir + \"do_file.csv\"\n",
    "done_file = root_dir + \"done_file.csv\"\n",
    "not_done_file = root_dir + \"not_done_file.csv\"\n",
    "\n",
    "# Reading the files\n",
    "import pandas as pd\n",
    "do_df = pd.read_csv(do_file, header=None, names=[\"Tickers\"])\n",
    "done_df = pd.read_csv(done_file, header=None, names=[\"Tickers\"])\n",
    "not_done_df = pd.read_csv(not_done_file, header=None, names=[\"Tickers\"])\n",
    "\n",
    "do_set = set(do_df[\"Tickers\"].tolist())\n",
    "done_set = set(done_df[\"Tickers\"].tolist())\n",
    "not_done_set = set(not_done_df[\"Tickers\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BFX14olzcdAi"
   },
   "outputs": [],
   "source": [
    "# URL Paths for Stockrow Website\n",
    "stockrow_url_paths = {\n",
    "    'company': 'https://stockrow.com/api/companies/',\n",
    "    'annual': {\n",
    "        'income-statement': '/financials.xlsx?dimension=MRY&section=Income%20Statement&sort=desc',\n",
    "        'balance-sheet': '/financials.xlsx?dimension=MRY&section=Balance%20Sheet&sort=desc',\n",
    "        'cashflow-statement': '/financials.xlsx?dimension=MRY&section=Cash%20Flow&sort=desc',\n",
    "        'metrics': '/financials.xlsx?dimension=MRY&section=Metrics&sort=desc',\n",
    "        'growth': '/financials.xlsx?dimension=MRY&section=Growth&sort=desc'\n",
    "    } \n",
    "}\n",
    "\n",
    "# Stockrow Downloader\n",
    "import requests\n",
    "def stockrow_download(ticker):\n",
    "    income_statement = pd.read_excel(stockrow_url_paths['company'] + ticker + stockrow_url_paths['annual'][\"income-statement\"], engine=\"xlrd\")\n",
    "    balance_sheet = pd.read_excel(stockrow_url_paths['company'] + ticker + stockrow_url_paths['annual'][\"balance-sheet\"], engine=\"xlrd\")\n",
    "    cashflow_statement = pd.read_excel(stockrow_url_paths['company'] + ticker + stockrow_url_paths['annual'][\"cashflow-statement\"], engine=\"xlrd\")\n",
    "    metrics = pd.read_excel(stockrow_url_paths['company'] + ticker + stockrow_url_paths['annual'][\"metrics\"], engine=\"xlrd\")\n",
    "    growth = pd.read_excel(stockrow_url_paths['company'] + ticker + stockrow_url_paths['annual'][\"growth\"], engine=\"xlrd\")\n",
    "    return income_statement, balance_sheet, cashflow_statement, metrics, growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yKRNeMGEcnT5"
   },
   "outputs": [],
   "source": [
    "# Modified Get Yahoo Quotes Script by Brad Luicas\n",
    "\n",
    "__author__ = \"Brad Luicas\"\n",
    "__copyright__ = \"Copyright 2017, Brad Lucas\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0.0\"\n",
    "__maintainer__ = \"Brad Lucas\"\n",
    "__email__ = \"brad@beaconhill.com\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "# import requests\n",
    "\n",
    "\n",
    "def split_crumb_store(v):\n",
    "    return v.split(':')[2].strip('\"')\n",
    "\n",
    "\n",
    "def find_crumb_store(lines):\n",
    "    # Looking for\n",
    "    # ,\"CrumbStore\":{\"crumb\":\"9q.A4D1c.b9\n",
    "    for l in lines:\n",
    "        if re.findall(r'CrumbStore', l):\n",
    "            return l\n",
    "    print(\"Did not find CrumbStore\")\n",
    "\n",
    "\n",
    "def get_cookie_value(r):\n",
    "    return {'B': r.cookies['B']}\n",
    "\n",
    "\n",
    "def get_page_data(symbol):\n",
    "    url = \"https://finance.yahoo.com/quote/%s/?p=%s\" % (symbol, symbol)\n",
    "    r = requests.get(url)\n",
    "    cookie = get_cookie_value(r)\n",
    "\n",
    "    # Code to replace possible \\u002F value\n",
    "    # ,\"CrumbStore\":{\"crumb\":\"FWP\\u002F5EFll3U\"\n",
    "    # FWP\\u002F5EFll3U\n",
    "    lines = r.content.decode('unicode-escape').strip(). replace('}', '\\n')\n",
    "    return cookie, lines.split('\\n')\n",
    "\n",
    "\n",
    "def get_cookie_crumb(symbol):\n",
    "    cookie, lines = get_page_data(symbol)\n",
    "    crumb = split_crumb_store(find_crumb_store(lines))\n",
    "    return cookie, crumb\n",
    "\n",
    "\n",
    "def get_data(symbol, start_date, end_date, cookie, crumb):\n",
    "    # filename = '%s.csv' % (symbol)\n",
    "    url = \"https://query1.finance.yahoo.com/v7/finance/download/%s?period1=%s&period2=%s&interval=1d&events=history&crumb=%s\" % (symbol, start_date, end_date, crumb)\n",
    "    response = requests.get(url, cookies=cookie)\n",
    "    # with open (filename, 'wb') as handle:\n",
    "    #     for block in response.iter_content(1024):\n",
    "    #         handle.write(block)\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_now_epoch():\n",
    "    # @see https://www.linuxquestions.org/questions/programming-9/python-datetime-to-epoch-4175520007/#post5244109\n",
    "    return int(time.time())\n",
    "\n",
    "\n",
    "def download_quotes(symbol):\n",
    "    start_date = 0\n",
    "    end_date = get_now_epoch()\n",
    "    cookie, crumb = get_cookie_crumb(symbol)\n",
    "    historical_prices = get_data(symbol, start_date, end_date, cookie, crumb)\n",
    "    return pd.read_csv(io.StringIO(historical_prices.content.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vPqPsju8cn9P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "def main():\n",
    "    counter = 0\n",
    "    total = len(do_set)\n",
    "    \n",
    "    print(do_set)\n",
    "    for ticker in do_set.copy():\n",
    "        counter = counter + 1\n",
    "        try:\n",
    "            print(\"Downloading data for: \" + ticker + \"(\" + str(counter) + \"/\" + str(total) +\"); Failed(\" + str(len(not_done_set)) + \")\")\n",
    "            income_statement, balance_sheet, cashflow_statement, metrics, growth = stockrow_download(ticker)\n",
    "            historical_prices = download_quotes(ticker)\n",
    "            with pd.ExcelWriter(root_dir + \"raw/\" + ticker + '.xlsx') as writer:\n",
    "                historical_prices.to_excel(writer, sheet_name=\"historical_prices\")\n",
    "                balance_sheet.to_excel(writer, sheet_name=\"balance_sheet\")\n",
    "                income_statement.to_excel(writer, sheet_name=\"income_statement\")\n",
    "                cashflow_statement.to_excel(writer, sheet_name=\"cashflow_statement\")\n",
    "                metrics.to_excel(writer, sheet_name=\"metrics\")\n",
    "                growth.to_excel(writer, sheet_name=\"growth\")\n",
    "        except:\n",
    "            not_done_set.add(ticker)\n",
    "            do_set.discard(ticker)\n",
    "            pd.DataFrame(list(not_done_set)).to_csv(not_done_file, header=None, index=False)\n",
    "            pd.DataFrame(list(do_set)).to_csv(do_file, header=None, index=False)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        done_set.add(ticker)\n",
    "        do_set.discard(ticker)\n",
    "        pd.DataFrame(list(done_set)).to_csv(done_file, header=None, index=False)\n",
    "        pd.DataFrame(list(not_done_set)).to_csv(not_done_file, header=None, index=False)\n",
    "        pd.DataFrame(list(do_set)).to_csv(do_file, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 182644,
     "status": "ok",
     "timestamp": 1553790774999,
     "user": {
      "displayName": "VIPUL SHARMA",
      "photoUrl": "https://lh6.googleusercontent.com/-B7fONb4kgNw/AAAAAAAAAAI/AAAAAAAABEo/XWJaOukizlg/s64/photo.jpg",
      "userId": "02912111327623795170"
     },
     "user_tz": -330
    },
    "id": "iFNtYbKCc-b6",
    "outputId": "9ecd213f-d863-4f38-9aca-63190729cafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ESRX', 'LUK', 'BRK.B', 'NFX', 'ANDV', 'AET', 'WYN', 'MON', 'CSRA', 'SCG', 'XL', 'PX', 'COL', 'SYK', 'GGP', 'UNP', 'HRL', 'BF.B', 'KORS'}\n",
      "Downloading data for: ESRX(1/19); Failed(0)\n",
      "Downloading data for: LUK(2/19); Failed(1)\n",
      "Downloading data for: BRK.B(3/19); Failed(2)\n",
      "Downloading data for: NFX(4/19); Failed(3)\n",
      "Downloading data for: ANDV(5/19); Failed(4)\n",
      "Downloading data for: GGP(6/19); Failed(5)\n",
      "Downloading data for: UNP(7/19); Failed(6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: invalid escape sequence '\\/'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for: AET(8/19); Failed(6)\n",
      "Downloading data for: WYN(9/19); Failed(7)\n",
      "Downloading data for: MON(10/19); Failed(8)\n",
      "Downloading data for: CSRA(11/19); Failed(9)\n",
      "Downloading data for: SCG(12/19); Failed(10)\n",
      "Downloading data for: XL(13/19); Failed(11)\n",
      "Downloading data for: PX(14/19); Failed(12)\n",
      "Downloading data for: COL(15/19); Failed(13)\n",
      "Downloading data for: SYK(16/19); Failed(14)\n",
      "Downloading data for: HRL(17/19); Failed(14)\n",
      "Downloading data for: BF.B(18/19); Failed(14)\n",
      "Downloading data for: KORS(19/19); Failed(15)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SP_Dataset_Framework.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
